{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["## Aumento de dados Mixup"]}, {"cell_type": "code", "execution_count": null, "metadata": {"hide_input": true}, "outputs": [], "source": ["from fastai.gen_doc.nbdoc import *\n", "from fastai.callbacks.mixup import *\n", "from fastai.vision import *\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## O que \u00e9 confus\u00e3o?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Este m\u00f3dulo cont\u00e9m a implementa\u00e7\u00e3o de uma t\u00e9cnica de aumento de dados chamado [mixup](https://arxiv.org/abs/1710.09412). \u00c9 extremamente eficiente na regulariza\u00e7\u00e3o modelos em vis\u00e3o computacional (que usamos para obter o nosso tempo para treinar CIFAR10 a 94% em uma GPU a 6 minutos).\n", "", "Como o nome tipo de sugere, os autores do artigo confus\u00e3o propor treinamento do modelo em misturas das imagens do conjunto de treinamento. Por exemplo, suponha que estamos treinando em CIFAR10. Em vez de alimentar o modelo das imagens cruas, tomamos duas imagens (n\u00e3o necessariamente da mesma classe) e fazer uma combina\u00e7\u00e3o linear deles: em termos de tensores, temos:\n", "", "`New_image = t * image1 + (1-t) * image2`\n", "", "onde t \u00e9 uma flutua\u00e7\u00e3o entre 0 e 1. O alvo vamos atribuir a essa nova imagem \u00e9 a mesma combina\u00e7\u00e3o das metas originais:\n", "", "`NEW_TARGET = t * target1 + (1-t) * target2`\n", "", "assumindo que os alvos s\u00e3o um-quente codificada (que n\u00e3o \u00e9 o caso em PyTorch normalmente). E \u00e9 t\u00e3o simples como isso.\n", "", "! XX_ markdown_link _xx\n", "", "C\u00e3o ou gato? A resposta aqui \u00e9 de 70% c\u00e3o e 30% do gato!\n", "", "Como a imagem acima mostra, \u00e9 um pouco dif\u00edcil para o olho humano a fazer sentido das imagens obtidas desta forma (embora n\u00f3s ver as formas de um c\u00e3o e um gato). No entanto, de alguma forma, faz muito sentido para o modelo, que treina de forma mais eficiente. Uma nota lateral importante \u00e9 que quando treinando com confus\u00e3o, a perda final (treinamento ou valida\u00e7\u00e3o) ser\u00e1 maior do que quando o treinamento sem ela, mesmo quando a precis\u00e3o \u00e9 muito melhor: um modelo treinados como este ir\u00e1 fazer previs\u00f5es que s\u00e3o um pouco menos confiantes ."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Treinamento b\u00e1sico"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Para testar este m\u00e9todo, primeiro criamos um [`simple_cnn`](/layers.html#simple_cnn) e trein\u00e1-lo como fizemos com [`basic_train`](/basic_train.html#basic_train) para que possamos comparar seus resultados com uma rede treinada com confus\u00e3o."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["path = untar_data(URLs.MNIST_SAMPLE)\n", "data = ImageDataBunch.from_folder(path)\n", "model = simple_cnn((3,16,16,2))\n", "learn = Learner(data, model, metrics=[accuracy])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"data": {"text/html": ["<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: left;\">\n", "      <th>epoch</th>\n", "      <th>train_loss</th>\n", "      <th>valid_loss</th>\n", "      <th>accuracy</th>\n", "      <th>time</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <td>1</td>\n", "      <td>0.111498</td>\n", "      <td>0.094612</td>\n", "      <td>0.965653</td>\n", "      <td>00:02</td>\n", "    </tr>\n", "    <tr>\n", "      <td>2</td>\n", "      <td>0.079887</td>\n", "      <td>0.064684</td>\n", "      <td>0.975466</td>\n", "      <td>00:02</td>\n", "    </tr>\n", "    <tr>\n", "      <td>3</td>\n", "      <td>0.053950</td>\n", "      <td>0.042022</td>\n", "      <td>0.985280</td>\n", "      <td>00:02</td>\n", "    </tr>\n", "    <tr>\n", "      <td>4</td>\n", "      <td>0.043062</td>\n", "      <td>0.035917</td>\n", "      <td>0.986752</td>\n", "      <td>00:02</td>\n", "    </tr>\n", "    <tr>\n", "      <td>5</td>\n", "      <td>0.030692</td>\n", "      <td>0.025291</td>\n", "      <td>0.989205</td>\n", "      <td>00:02</td>\n", "    </tr>\n", "    <tr>\n", "      <td>6</td>\n", "      <td>0.027065</td>\n", "      <td>0.024845</td>\n", "      <td>0.987733</td>\n", "      <td>00:02</td>\n", "    </tr>\n", "    <tr>\n", "      <td>7</td>\n", "      <td>0.031135</td>\n", "      <td>0.020047</td>\n", "      <td>0.990186</td>\n", "      <td>00:02</td>\n", "    </tr>\n", "    <tr>\n", "      <td>8</td>\n", "      <td>0.025115</td>\n", "      <td>0.025447</td>\n", "      <td>0.988714</td>\n", "      <td>00:02</td>\n", "    </tr>\n", "  </tbody>\n", "</table>"], "text/plain": ["<IPython.core.display.HTML object>"]}, "metadata": {}, "output_type": "display_data"}], "source": ["learn.fit(8)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## implementa\u00e7\u00e3o confus\u00e3o na biblioteca"]}, {"cell_type": "markdown", "metadata": {}, "source": ["No artigo original, os autores sugerem quatro coisas:\n", "", "1. Crie dois DataLoaders separadas, e desenhar um lote de cada em cada itera\u00e7\u00e3o para mistur\u00e1-las\n", "2. Desenhar um valor para t na sequ\u00eancia de uma distribui\u00e7\u00e3o beta com uma alfa par\u00e2metro (0,4 \u00e9 sugerido no seu artigo)\n", "3. Misturar os dois lotes, com o mesmo valor t\n", "4. Use one-quentes alvos codificados\n", "", "A implementa\u00e7\u00e3o deste m\u00f3dulo \u00e9 baseado nessas sugest\u00f5es, e modificado onde os resultados experimentais sugeriram mudan\u00e7as que melhoram o desempenho."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Os autores sugerem a utiliza\u00e7\u00e3o da distribui\u00e7\u00e3o beta com par\u00e2metros alfa = 0,4. (Em geral, a distribui\u00e7\u00e3o beta tem dois par\u00e2metros, mas neste caso eles v\u00e3o ser iguais.) Por que eles sugerem isso? Bem, com os par\u00e2metros que eles sugerem, a distribui\u00e7\u00e3o beta parece com isso:\n", "", "! XX_ markdown_link _xx\n", "", "o que significa que h\u00e1 uma probabilidade muito elevada de valores colhendo perto de 0 ou 1 (caso em que a imagem misturado \u00e9 principalmente a partir de apenas uma categoria) e, em seguida, um pouco constante, muito menor probabilidade de escolher algo no meio (note que 0,33 \u00e9 quase t\u00e3o suscept\u00edveis como 0,5, por exemplo).\n", "", "Enquanto isso funciona muito bem, n\u00e3o \u00e9 a maneira mais r\u00e1pida, e esta \u00e9 a primeira sugest\u00e3o que ajustar. A desacelera\u00e7\u00e3o desnecess\u00e1ria com esta abordagem vem de desenho dois lotes diferentes em cada itera\u00e7\u00e3o, o que significa carregar duas vezes o n\u00famero de imagens e, adicionalmente, aplicar quaisquer outras fun\u00e7\u00f5es de aumento de dados para eles. Para evitar isso, n\u00f3s aplicamos confus\u00e3o em um lote com uma vers\u00e3o embaralhadas de si mesmo: desta forma, as imagens misturadas ainda s\u00e3o diferentes.\n", "", "Usando o mesmo valor de `t` para todo o lote \u00e9 outra sugest\u00e3o que modificar. Em nossos experimentos, observamos que o modelo treinado mais r\u00e1pido se desenhou um `t` diferente para cada imagem no lote. (Ambas as op\u00e7\u00f5es tem o mesmo resultado em termos de precis\u00e3o, \u00e9 apenas que um chegou h\u00e1 mais lentamente.)\n", "", "Finalmente, observe que, com esta estrat\u00e9gia que pode criar imagens duplicadas: digamos que estamos misturando `image0` com` image1` e `image1` com` image0`, e que chamamos `t = 0.1` pela primeira mix e` t = 0.9` para o segundo. Ent\u00e3o\n", "", "`Image0 * 0,1 + shuffle0 * (1-0,1) = image0 * 0,1 + image1 * 0.9`\n", "", "e\n", "", "`Image1 * 0,9 + shuffle1 * (1-0,9) = image1 * 0.9 + * image0 0.1`\n", "", "ser\u00e1 o mesmo. \u00c9 claro que temos que ser um pouco de azar para que isso aconte\u00e7a, mas, na pr\u00e1tica, vimos uma queda na precis\u00e3o quando n\u00e3o remover duplicatas. Para evitar isso, o truque \u00e9 substituir o vetor de `t` que empatou com:\n", "", "`T = max (t, 1-t)`\n", "", "A distribui\u00e7\u00e3o beta com os dois par\u00e2metros iguais \u00e9 sim\u00e9trica, em qualquer caso, e desta forma podemos garantir que o maior coeficiente \u00e9 sempre perto da primeira imagem (o lote n\u00e3o embaralhadas)."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Adicionando confus\u00e3o \u00e0 mistura"]}, {"cell_type": "markdown", "metadata": {}, "source": ["N\u00f3s agora adicionar [`MixUpCallback`](/callbacks.mixup.html#MixUpCallback) ao nosso aluno para que ele modifica a nossa entrada e alvo em conformidade. A fun\u00e7\u00e3o [`mixup`](/train.html#mixup) faz isso para n\u00f3s nos bastidores, junto com alguns outros ajustes descritos abaixo:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"hide_input": false}, "outputs": [{"data": {"text/html": ["<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: left;\">\n", "      <th>epoch</th>\n", "      <th>train_loss</th>\n", "      <th>valid_loss</th>\n", "      <th>accuracy</th>\n", "      <th>time</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <td>1</td>\n", "      <td>0.358743</td>\n", "      <td>0.156058</td>\n", "      <td>0.961236</td>\n", "      <td>00:02</td>\n", "    </tr>\n", "    <tr>\n", "      <td>2</td>\n", "      <td>0.334059</td>\n", "      <td>0.124648</td>\n", "      <td>0.982336</td>\n", "      <td>00:02</td>\n", "    </tr>\n", "    <tr>\n", "      <td>3</td>\n", "      <td>0.321510</td>\n", "      <td>0.105825</td>\n", "      <td>0.987242</td>\n", "      <td>00:02</td>\n", "    </tr>\n", "    <tr>\n", "      <td>4</td>\n", "      <td>0.314596</td>\n", "      <td>0.099804</td>\n", "      <td>0.988714</td>\n", "      <td>00:02</td>\n", "    </tr>\n", "    <tr>\n", "      <td>5</td>\n", "      <td>0.314716</td>\n", "      <td>0.094472</td>\n", "      <td>0.989205</td>\n", "      <td>00:02</td>\n", "    </tr>\n", "    <tr>\n", "      <td>6</td>\n", "      <td>0.309679</td>\n", "      <td>0.095133</td>\n", "      <td>0.989696</td>\n", "      <td>00:02</td>\n", "    </tr>\n", "    <tr>\n", "      <td>7</td>\n", "      <td>0.314474</td>\n", "      <td>0.086767</td>\n", "      <td>0.990186</td>\n", "      <td>00:02</td>\n", "    </tr>\n", "    <tr>\n", "      <td>8</td>\n", "      <td>0.309931</td>\n", "      <td>0.095609</td>\n", "      <td>0.990186</td>\n", "      <td>00:02</td>\n", "    </tr>\n", "  </tbody>\n", "</table>"], "text/plain": ["<IPython.core.display.HTML object>"]}, "metadata": {}, "output_type": "display_data"}], "source": ["model = simple_cnn((3,16,16,2))\n", "learner = Learner(data, model, metrics=[accuracy]).mixup()\n", "learner.fit(8)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Treinar com confus\u00e3o melhora a melhor precis\u00e3o. Note-se que a perda de valida\u00e7\u00e3o \u00e9 maior do que sem confus\u00e3o, porque o modelo faz previs\u00f5es menos confiantes: sem confus\u00e3o, a maioria das previs\u00f5es est\u00e3o muito perto de 0. ou 1. (em termos de probabilidade), enquanto que o modelo com confus\u00e3o faz previs\u00f5es que s\u00e3o mais nuan\u00e7ada . Antes de usar confus\u00e3o, certifique-se de saber se \u00e9 mais importante para otimizar a perda inferior ou melhor precis\u00e3o."]}, {"cell_type": "code", "execution_count": null, "metadata": {"hide_input": true}, "outputs": [{"data": {"text/markdown": ["<h2 id=\"MixUpCallback\" class=\"doc_header\"><code>class</code> <code>MixUpCallback</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/callbacks/mixup.py#L8\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#MixUpCallback-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h2>\n", "\n", "> <code>MixUpCallback</code>(**`learn`**:[`Learner`](/basic_train.html#Learner), **`alpha`**:`float`=***`0.4`***, **`stack_x`**:`bool`=***`False`***, **`stack_y`**:`bool`=***`True`***) :: [`LearnerCallback`](/basic_train.html#LearnerCallback)\n", "\n", "<div class=\"collapse\" id=\"MixUpCallback-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#MixUpCallback-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>MixUpCallback</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div>\n", "\n", "Callback that creates the mixed-up input and target.  "], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}], "source": ["show_doc(MixUpCallback)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Criar um [`Callback`](/callback.html#Callback) para confus\u00e3o sobre `learn` com um par\u00e2metro alpha`` para a distribui\u00e7\u00e3o beta. `Stack_x` e` stack_y` determinar se n\u00f3s empilhamos nossas entradas / alvos com o lambda vetor tirada ou fazer a combina\u00e7\u00e3o linear. (Em geral, empilhar as entradas ou sa\u00eddas quando correspondem a categorias ou classes e fazer a combina\u00e7\u00e3o linear de outra forma.)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### m\u00e9todos de retorno de chamada"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Voc\u00ea n\u00e3o chama esses mesmo - eles s\u00e3o chamados pelo sistema [`Callback`](/callback.html#Callback) das fastai automaticamente para ativar a funcionalidade da classe."]}, {"cell_type": "code", "execution_count": null, "metadata": {"hide_input": true}, "outputs": [{"data": {"text/markdown": ["<h4 id=\"MixUpCallback.on_batch_begin\" class=\"doc_header\"><code>on_batch_begin</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/callbacks/mixup.py#L17\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#MixUpCallback-on_batch_begin-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h4>\n", "\n", "> <code>on_batch_begin</code>(**`last_input`**, **`last_target`**, **`train`**, **\\*\\*`kwargs`**)\n", "\n", "<div class=\"collapse\" id=\"MixUpCallback-on_batch_begin-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#MixUpCallback-on_batch_begin-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>on_batch_begin</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div>\n", "\n", "Applies mixup to `last_input` and `last_target` if `train`.  "], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}], "source": ["show_doc(MixUpCallback.on_batch_begin)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Chama a um vector de lambda ap\u00f3s uma distribui\u00e7\u00e3o beta com `self.alpha` e opera a confus\u00e3o no` e `last_input` last_target` de acordo com a` `self.stack_x` e self.stack_y`."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Lidando com a perda"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Muitas vezes temos de modificar a perda de modo que seja compat\u00edvel com a confus\u00e3o. PyTorch era muito cuidadoso para evitar alvos de codifica\u00e7\u00e3o one-quentes, quando poss\u00edvel, de modo que parece um pouco de arrastar para desfazer isso. Felizmente para n\u00f3s, se a perda \u00e9 um [cross-entropy](https://pytorch.org/docs/stable/nn.html#torch.nn.functional.cross_entropy) cl\u00e1ssico, temos\n", "", "`Perda (sa\u00edda, NEW_TARGET) = t * perda (sa\u00edda, target1) + (1-t) * perda (sa\u00edda, target2)`\n", "", "Ent\u00e3o, n\u00f3s n\u00e3o one-quente codificar qualquer coisa e, em vez apenas calcular essas duas perdas e encontrar a combina\u00e7\u00e3o linear.\n", "", "A classe a seguir \u00e9 usado para adaptar a perda de confus\u00e3o. Note que a fun\u00e7\u00e3o [`mixup`](/train.html#mixup) vai us\u00e1-lo para mudar o `Learner.loss_func` se necess\u00e1rio."]}, {"cell_type": "code", "execution_count": null, "metadata": {"hide_input": true}, "outputs": [{"data": {"text/markdown": ["<h3 id=\"MixUpLoss\" class=\"doc_header\"><code>class</code> <code>MixUpLoss</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/callbacks/mixup.py#L42\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#MixUpLoss-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h3>\n", "\n", "> <code>MixUpLoss</code>(**`crit`**, **`reduction`**=***`'mean'`***) :: [`PrePostInitMeta`](/core.html#PrePostInitMeta) :: [`Module`](/torch_core.html#Module)\n", "\n", "<div class=\"collapse\" id=\"MixUpLoss-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#MixUpLoss-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>MixUpLoss</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div>\n", "\n", "Adapt the loss function `crit` to go with mixup.  "], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}], "source": ["show_doc(MixUpLoss, title_level=3)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Indocumentados M\u00e9todos - M\u00e9todos movidos abaixo desta linha ir\u00e1 intencionalmente ser escondido"]}, {"cell_type": "code", "execution_count": null, "metadata": {"hide_input": true}, "outputs": [{"data": {"text/markdown": ["<h4 id=\"MixUpLoss.forward\" class=\"doc_header\"><code>forward</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/callbacks/mixup.py#L56\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#MixUpLoss-forward-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h4>\n", "\n", "> <code>forward</code>(**`output`**, **`target`**)\n", "\n", "<div class=\"collapse\" id=\"MixUpLoss-forward-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#MixUpLoss-forward-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>forward</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div>\n", "\n", "Defines the computation performed at every call. Should be overridden by all subclasses.\n", "\n", ".. note::\n", "    Although the recipe for forward pass needs to be defined within\n", "    this function, one should call the :class:[`Module`](/torch_core.html#Module) instance afterwards\n", "    instead of this since the former takes care of running the\n", "    registered hooks while the latter silently ignores them. "], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}], "source": ["show_doc(MixUpLoss.forward)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}], "metadata": {"jekyll": {"keywords": "fastai", "summary": "Implementation of mixup", "title": "callbacks.mixup"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}, "nbformat": 4, "nbformat_minor": 2}