{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["## Implementa\u00e7\u00e3o dos modelos de linguagem"]}, {"cell_type": "code", "execution_count": null, "metadata": {"hide_input": true}, "outputs": [], "source": ["from fastai.gen_doc.nbdoc import *\n", "from fastai.text import * \n", "from fastai.text.models import * "]}, {"cell_type": "markdown", "metadata": {}, "source": ["[`text.models`](/text.models.html#text.models) m\u00f3dulo implementa totalmente o codificador para um [AWD-LSTM](https://arxiv.org/pdf/1708.02182.pdf), o [transformer model](https://arxiv.org/abs/1706.03762) e o [transformer XL model](https://arxiv.org/abs/1901.02860). Eles podem ent\u00e3o ligado com um descodificador para fazer um modelo de linguagem, ou algumas camadas de classifica\u00e7\u00e3o para fazer um classificador de texto."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## m\u00f3dulos de modelo Idioma"]}, {"cell_type": "code", "execution_count": null, "metadata": {"hide_input": false}, "outputs": [{"data": {"text/markdown": ["<h3 id=\"AWD_LSTM\" class=\"doc_header\"><code>class</code> <code>AWD_LSTM</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/models/awd_lstm.py#L75\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#AWD_LSTM-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h3>\n", "\n", "> <code>AWD_LSTM</code>(**`vocab_sz`**:`int`, **`emb_sz`**:`int`, **`n_hid`**:`int`, **`n_layers`**:`int`, **`pad_token`**:`int`=***`1`***, **`hidden_p`**:`float`=***`0.2`***, **`input_p`**:`float`=***`0.6`***, **`embed_p`**:`float`=***`0.1`***, **`weight_p`**:`float`=***`0.5`***, **`qrnn`**:`bool`=***`False`***, **`bidir`**:`bool`=***`False`***) :: [`PrePostInitMeta`](/core.html#PrePostInitMeta) :: [`Module`](/torch_core.html#Module)\n", "\n", "<div class=\"collapse\" id=\"AWD_LSTM-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#AWD_LSTM-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>AWD_LSTM</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div>\n", "\n", "AWD-LSTM/QRNN inspired by https://arxiv.org/abs/1708.02182.  "], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}], "source": ["show_doc(AWD_LSTM, title_level=3)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["A id\u00e9ia principal do artigo \u00e9 usar um [RNN](http://www.pnas.org/content/79/8/2554) ao abandono em todos os lugares, mas de uma forma inteligente. H\u00e1 uma diferen\u00e7a com o abandono de costume, raz\u00e3o pela qual voc\u00ea ver\u00e1 um m\u00f3dulo [`RNNDropout`](/text.models.awd_lstm.html#RNNDropout): n\u00f3s zerar as coisas, como \u00e9 habitual em abandono, mas n\u00f3s sempre zero a mesma coisa de acordo com a dimens\u00e3o seq\u00fc\u00eancia (que \u00e9 a primeira dimens\u00e3o em pytorch ). Isso garante consist\u00eancia ao atualizar o estado oculto atrav\u00e9s das frases inteiras / artigos.\n", "", "Esta sendo dada, h\u00e1 um total de quatro desist\u00eancias diferentes no codificador da AWD-LSTM:\n", "", "- a primeira, a incorpora\u00e7\u00e3o de abandono, \u00e9 aplicada quando olhamos os ids de nossas fichas no interior da matriz de encastre (para transform\u00e1-los a partir de n\u00fameros de um vector de flutuador). N\u00f3s zerar algumas linhas do mesmo, assim ids aleat\u00f3rios s\u00e3o enviados para um vetor de zeros em vez de serem enviados para o seu vector de incorpora\u00e7\u00e3o. Este \u00e9 o par\u00e2metro `embed_p`.\n", "- o segundo, o abandono de entrada, \u00e9 aplicada ao resultado da incorpora\u00e7\u00e3o com abandono. Esquecemo-nos de peda\u00e7os aleat\u00f3rios de matriz incorpora\u00e7\u00e3o (mas como indicado no \u00faltimo par\u00e1grafo, os mesmos na dimens\u00e3o seq\u00fc\u00eancia). Este \u00e9 o par\u00e2metro `input_p`.\n", "- o terceiro \u00e9 o abandono peso. \u00c9 o mais complicado de implementar como podemos substituir aleatoriamente por 0s alguns pesos da matriz oculta-se escondido dentro da RNN: isso precisa ser feito de uma forma que garantir os gradientes ainda s\u00e3o computados e os pesos iniciais ainda atualizado. Este \u00e9 o par\u00e2metro `weight_p`.\n", "- o quarto \u00e9 o abandono escondido. \u00c9 aplicada \u00e0 sa\u00edda de uma das camadas da RNN antes de ser usado como entrada da camada pr\u00f3xima (novamente mesmas coordenadas s\u00e3o postas em zero na dimens\u00e3o sequ\u00eancia). N\u00e3o \u00e9 aplicado \u00e0 \u00faltima sa\u00edda (que vai ter o seu pr\u00f3prio abandono no decodificador) .Este \u00e9 o par\u00e2metro `hidden_p`.\n", "", "Os outros atributos s\u00e3o `vocab_sz` para o n\u00famero de fichas na sua vocabul\u00e1rio,` emb_sz` para o tamanho incorpora\u00e7\u00e3o, `n_hid` para o tamanho escondido dos seus LSTMs interiores (ou QRNNs),` n_layers` o n\u00famero de camadas e `pad_token `para o \u00edndice de um s\u00edmbolo de enchimento eventual (1 por padr\u00e3o em fastai).\n", "", "A bandeira `qrnn = true` substituir os LSTMs interiores por [QRNNs](https://arxiv.org/abs/1611.01576)."]}, {"cell_type": "code", "execution_count": null, "metadata": {"hide_input": true}, "outputs": [{"data": {"text/markdown": ["<h4 id=\"AWD_LSTM.reset\" class=\"doc_header\"><code>reset</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/models/awd_lstm.py#L130\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#AWD_LSTM-reset-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h4>\n", "\n", "> <code>reset</code>()\n", "\n", "<div class=\"collapse\" id=\"AWD_LSTM-reset-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#AWD_LSTM-reset-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>reset</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div>\n", "\n", "Reset the hidden states.  "], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}], "source": ["show_doc(AWD_LSTM.reset)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"hide_input": false}, "outputs": [{"data": {"text/markdown": ["<h3 id=\"Transformer\" class=\"doc_header\"><code>class</code> <code>Transformer</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/models/transformer.py#L149\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#Transformer-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h3>\n", "\n", "> <code>Transformer</code>(**`vocab_sz`**:`int`, **`ctx_len`**:`int`, **`n_layers`**:`int`, **`n_heads`**:`int`, **`d_model`**:`int`, **`d_head`**:`int`, **`d_inner`**:`int`, **`resid_p`**:`float`=***`0.0`***, **`attn_p`**:`float`=***`0.0`***, **`ff_p`**:`float`=***`0.0`***, **`embed_p`**:`float`=***`0.0`***, **`bias`**:`bool`=***`True`***, **`scale`**:`bool`=***`True`***, **`act`**:[`Activation`](/text.models.transformer.html#Activation)=***`<Activation.ReLU: 1>`***, **`double_drop`**:`bool`=***`True`***, **`attn_cls`**:`Callable`=***`'MultiHeadAttention'`***, **`learned_pos_enc`**:`bool`=***`True`***, **`mask`**:`bool`=***`True`***) :: [`PrePostInitMeta`](/core.html#PrePostInitMeta) :: [`Module`](/torch_core.html#Module)\n", "\n", "<div class=\"collapse\" id=\"Transformer-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#Transformer-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>Transformer</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div>\n", "\n", "Transformer model: https://arxiv.org/abs/1706.03762.  "], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}], "source": ["show_doc(Transformer, title_level=3)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["A id\u00e9ia principal deste artigo \u00e9 a utiliza\u00e7\u00e3o de rede neural regular para NLP em vez de uma RNN, mas com muitas camadas de aten\u00e7\u00e3o. Intuitivamente, essas camadas de aten\u00e7\u00e3o dizer o modelo que pagar mais juros a este ou \u00e0quele mundo quando se tenta prever a sua sa\u00edda.\n", "", "Ele come\u00e7a a partir de mergulhos de `vocab_sz` (n\u00famero de fichas) para` d_model` (que \u00e9 basicamente o tamanho escondido em todo o modelo), e ele vai olhar para entradas de tamanho batch_size por `ctx_len` (para o comprimento do contexto). N\u00f3s adicionamos uma codifica\u00e7\u00e3o posicional para os mergulhos (uma vez que uma rede neural normal n\u00e3o tem id\u00e9ia da ordem de palavras), seja aprendido ou provenientes de [`PositionalEncoding`](/text.models.transformer.html#PositionalEncoding) dependendo `learned_pos_enc`. Temos, ent\u00e3o, uma sa\u00edda de `embed_p` seguido por 'blocos n_layers` de [`MultiHeadAttention`](/text.models.transformer.html#MultiHeadAttention) seguido por [`feed_forward`](/text.models.transformer.html#feed_forward).\n", "", "Na aten\u00e7\u00e3o que usar `n_heads` com cada um estado oculto de` d_head` (ser\u00e1 o padr\u00e3o para `d_model // n_heads`). Se `m\u00e1scara = true`, uma m\u00e1scara ir\u00e1 certificar-se nenhuma aten\u00e7\u00e3o \u00e9 dada para os tokens futuros (que seria batota ao treinar um modelo de linguagem). Se `escala = TRUE, as pontua\u00e7\u00f5es de aten\u00e7\u00e3o s\u00e3o escalonadas por um factor de 1` / Math.sqrt (d_head) `. Um abandono do `attn_p` \u00e9 aplicada \u00e0s contagens de aten\u00e7\u00e3o, ent\u00e3o o resultado final se aplicada uma sa\u00edda de` resid_p` antes de serem somadas para a entrada original (liga\u00e7\u00e3o residual antes de a norma camada).\n", "", "Na alimenta\u00e7\u00e3o para a frente, que tem duas camadas lineares de d_model` `a` d_inner` e, em seguida, de volta. Aqueles t\u00eam `bias` se que a bandeira \u00e9` true` e uma sa\u00edda de `ff_p` \u00e9 aplicada, depois de cada um, se double_drop` = TRUE, ou apenas no final de outra forma. `Act` \u00e9 utilizada no meio como um n\u00e3o-linearidade."]}, {"cell_type": "code", "execution_count": null, "metadata": {"hide_input": false}, "outputs": [{"data": {"text/markdown": ["<h3 id=\"TransformerXL\" class=\"doc_header\"><code>class</code> <code>TransformerXL</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/models/transformer.py#L175\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#TransformerXL-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h3>\n", "\n", "> <code>TransformerXL</code>(**`vocab_sz`**:`int`, **`ctx_len`**:`int`, **`n_layers`**:`int`, **`n_heads`**:`int`, **`d_model`**:`int`, **`d_head`**:`int`, **`d_inner`**:`int`, **`resid_p`**:`float`=***`0.0`***, **`attn_p`**:`float`=***`0.0`***, **`ff_p`**:`float`=***`0.0`***, **`embed_p`**:`float`=***`0.0`***, **`bias`**:`bool`=***`False`***, **`scale`**:`bool`=***`True`***, **`act`**:[`Activation`](/text.models.transformer.html#Activation)=***`<Activation.ReLU: 1>`***, **`double_drop`**:`bool`=***`True`***, **`attn_cls`**:`Callable`=***`'MultiHeadRelativeAttention'`***, **`learned_pos_enc`**:`bool`=***`False`***, **`mask`**:`bool`=***`True`***, **`mem_len`**:`int`=***`0`***) :: [`PrePostInitMeta`](/core.html#PrePostInitMeta) :: [`Module`](/torch_core.html#Module)\n", "\n", "<div class=\"collapse\" id=\"TransformerXL-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#TransformerXL-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>TransformerXL</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div>\n", "\n", "TransformerXL model: https://arxiv.org/abs/1901.02860.  "], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}], "source": ["show_doc(TransformerXL, title_level=3)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["TransformerXL \u00e9 uma arquitetura de transformador com um tipo de estado escondido formado pelos resultados das camadas interm\u00e9dias em fichas anteriores. O seu tamanho \u00e9 determinado por `mem_len`. Ao utilizar este contexto, esses modelos s\u00e3o capazes de aprender depend\u00eancias mais longos e tamb\u00e9m pode ser usado para gera\u00e7\u00e3o de texto mais r\u00e1pido em infer\u00eancia: um modelo transformador normal teria de reexaminar toda a seq\u00fc\u00eancia de \u00edndices gerados at\u00e9 agora, enquanto podemos alimentar os novos tokens um por um para um transformador XL (como fazemos com um RNN regular)."]}, {"cell_type": "code", "execution_count": null, "metadata": {"hide_input": false}, "outputs": [{"data": {"text/markdown": ["<h4 id=\"TransformerXL.reset\" class=\"doc_header\"><code>reset</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/models/transformer.py#L192\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#TransformerXL-reset-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h4>\n", "\n", "> <code>reset</code>()\n", "\n", "<div class=\"collapse\" id=\"TransformerXL-reset-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#TransformerXL-reset-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>reset</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div>\n", "\n", "Reset the internal memory.  "], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}], "source": ["show_doc(TransformerXL.reset)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Descodificadores"]}, {"cell_type": "code", "execution_count": null, "metadata": {"hide_input": false}, "outputs": [{"data": {"text/markdown": ["<h3 id=\"LinearDecoder\" class=\"doc_header\"><code>class</code> <code>LinearDecoder</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/models/awd_lstm.py#L136\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#LinearDecoder-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h3>\n", "\n", "> <code>LinearDecoder</code>(**`n_out`**:`int`, **`n_hid`**:`int`, **`output_p`**:`float`, **`tie_encoder`**:[`Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)=***`None`***, **`bias`**:`bool`=***`True`***) :: [`PrePostInitMeta`](/core.html#PrePostInitMeta) :: [`Module`](/torch_core.html#Module)\n", "\n", "<div class=\"collapse\" id=\"LinearDecoder-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#LinearDecoder-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>LinearDecoder</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div>\n", "\n", "To go on top of a RNNCore module and create a Language Model.  "], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}], "source": ["show_doc(LinearDecoder, title_level=3)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Criar um decodificador para ir em cima de um codificador [`RNNCore`](/text.models.awd_lstm.html#RNNCore) e criar um modelo de linguagem. `N_hid` \u00e9 a dimens\u00e3o do \u00faltimo estado escondido do codificador,` n_out` o tamanho da sa\u00edda. Abandono do `output_p` \u00e9 aplicado. Se um `tie_encoder` \u00e9 passado, ele ser\u00e1 usado para os pesos da camada linear, que ter\u00e3o` bias` ou n\u00e3o."]}, {"cell_type": "code", "execution_count": null, "metadata": {"hide_input": false}, "outputs": [{"data": {"text/markdown": ["<h3 id=\"PoolingLinearClassifier\" class=\"doc_header\"><code>class</code> <code>PoolingLinearClassifier</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/learner.py#L230\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#PoolingLinearClassifier-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h3>\n", "\n", "> <code>PoolingLinearClassifier</code>(**`layers`**:`Collection`\\[`int`\\], **`drops`**:`Collection`\\[`float`\\]) :: [`PrePostInitMeta`](/core.html#PrePostInitMeta) :: [`Module`](/torch_core.html#Module)\n", "\n", "<div class=\"collapse\" id=\"PoolingLinearClassifier-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#PoolingLinearClassifier-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>PoolingLinearClassifier</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div>\n", "\n", "Create a linear classifier with pooling.  "], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}], "source": ["show_doc(PoolingLinearClassifier, title_level=3)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["A \u00faltima sa\u00edda, `MaxPooling` de todas as sa\u00eddas e` AvgPooling` de todas as sa\u00eddas s\u00e3o concatenados, ent\u00e3o os blocos s\u00e3o empilhados de [`bn_drop_lin`](/layers.html#bn_drop_lin), de acordo com os valores em [`layers`](/layers.html#layers) e `drops`."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## m\u00f3dulos b\u00e1sicos da PNL"]}, {"cell_type": "markdown", "metadata": {}, "source": ["No topo da pytorch ou o [`layers`](/layers.html#layers) fastai, os modelos de linguagem usar algumas camadas personalizados espec\u00edficos para PNL."]}, {"cell_type": "code", "execution_count": null, "metadata": {"hide_input": true}, "outputs": [{"data": {"text/markdown": ["<h3 id=\"EmbeddingDropout\" class=\"doc_header\"><code>class</code> <code>EmbeddingDropout</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/models/awd_lstm.py#L57\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#EmbeddingDropout-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h3>\n", "\n", "> <code>EmbeddingDropout</code>(**`emb`**:[`Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module), **`embed_p`**:`float`) :: [`PrePostInitMeta`](/core.html#PrePostInitMeta) :: [`Module`](/torch_core.html#Module)\n", "\n", "<div class=\"collapse\" id=\"EmbeddingDropout-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#EmbeddingDropout-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>EmbeddingDropout</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div>\n", "\n", "Apply dropout with probabily `embed_p` to an embedding layer `emb`.  "], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}], "source": ["show_doc(EmbeddingDropout, title_level=3)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Cada linha da matriz incorpora\u00e7\u00e3o tem uma probabilidade `embed_p` de ser substitu\u00eddo por zeros, enquanto os outros s\u00e3o rescaled em conformidade."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"data": {"text/plain": ["tensor([[-0.7379, -1.3970, -0.4075, -0.1676,  2.0396,  3.2226,  0.7128],\n", "        [-0.0000,  0.0000,  0.0000, -0.0000, -0.0000,  0.0000,  0.0000],\n", "        [-3.2579,  2.2972, -1.8704, -0.4090,  2.6477, -1.5015,  0.7158],\n", "        [ 2.1455,  1.0571, -0.6086,  3.5700,  2.6271, -3.1353,  0.7277],\n", "        [-3.7003, -1.8846,  0.2029, -0.6839,  0.2968, -2.0199,  1.3127],\n", "        [-0.0000,  0.0000, -0.0000, -0.0000,  0.0000,  0.0000, -0.0000],\n", "        [-0.0051,  2.7428,  3.0068,  0.6242,  1.2747,  0.9262,  0.4070],\n", "        [ 1.9312,  3.0524, -1.2806,  1.5910, -2.1789, -0.1636, -3.4924]],\n", "       grad_fn=<EmbeddingBackward>)"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["enc = nn.Embedding(100, 7, padding_idx=1)\n", "enc_dp = EmbeddingDropout(enc, 0.5)\n", "tst_input = torch.randint(0,100,(8,))\n", "enc_dp(tst_input)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"hide_input": true}, "outputs": [{"data": {"text/markdown": ["<h3 id=\"RNNDropout\" class=\"doc_header\"><code>class</code> <code>RNNDropout</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/models/awd_lstm.py#L17\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#RNNDropout-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h3>\n", "\n", "> <code>RNNDropout</code>(**`p`**:`float`=***`0.5`***) :: [`PrePostInitMeta`](/core.html#PrePostInitMeta) :: [`Module`](/torch_core.html#Module)\n", "\n", "<div class=\"collapse\" id=\"RNNDropout-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#RNNDropout-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>RNNDropout</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div>\n", "\n", "Dropout with probability `p` that is consistent on the seq_len dimension.  "], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}], "source": ["show_doc(RNNDropout, title_level=3)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"data": {"text/plain": ["(tensor([[[-2.1156,  0.9734,  0.2428,  0.9396,  0.4072, -0.8197,  0.3718],\n", "          [ 0.4838,  1.3077, -0.8239, -0.6557,  1.3938,  0.6086, -0.2622],\n", "          [ 0.2372, -0.1627,  0.3117, -0.4811, -1.0841, -0.5207, -0.5131]],\n", " \n", "         [[-0.6924,  0.4122,  0.2517, -1.0120,  0.6808,  0.8800, -0.7463],\n", "          [-0.9498,  0.7655,  0.7471, -0.2767,  1.2155, -0.1042, -2.1443],\n", "          [-1.2342,  1.9187, -0.8481, -0.4115, -1.3223,  1.4266, -1.4150]],\n", " \n", "         [[ 0.1539,  0.3142,  0.2158,  1.1411,  0.1316,  0.6158, -1.5078],\n", "          [-1.0177, -0.9230,  0.9994,  0.1140,  0.7432,  0.4353,  0.0096],\n", "          [-0.8231,  1.0086,  1.7685,  0.3304, -0.0896, -1.0513, -1.3017]]]),\n", " tensor([[[-3.0223,  1.3905,  0.0000,  0.0000,  0.5818, -0.0000,  0.5312],\n", "          [ 0.6911,  1.8681, -0.0000, -0.0000,  1.9911,  0.0000, -0.3745],\n", "          [ 0.3389, -0.2324,  0.0000, -0.0000, -1.5487, -0.0000, -0.7331]],\n", " \n", "         [[-0.9892,  0.5889,  0.3596, -1.4458,  0.9725,  1.2571, -0.0000],\n", "          [-1.3569,  1.0936,  1.0673, -0.3953,  1.7364, -0.1489, -0.0000],\n", "          [-1.7631,  2.7410, -1.2116, -0.5879, -1.8889,  2.0380, -0.0000]],\n", " \n", "         [[ 0.0000,  0.4489,  0.0000,  1.6301,  0.1880,  0.8797, -2.1539],\n", "          [-0.0000, -1.3186,  0.0000,  0.1628,  1.0617,  0.6218,  0.0137],\n", "          [-0.0000,  1.4408,  0.0000,  0.4720, -0.1280, -1.5019, -1.8595]]]))"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["dp = RNNDropout(0.3)\n", "tst_input = torch.randn(3,3,7)\n", "tst_input, dp(tst_input)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"hide_input": true}, "outputs": [{"data": {"text/markdown": ["<h3 id=\"WeightDropout\" class=\"doc_header\"><code>class</code> <code>WeightDropout</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/models/awd_lstm.py#L27\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#WeightDropout-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h3>\n", "\n", "> <code>WeightDropout</code>(**`module`**:[`Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module), **`weight_p`**:`float`, **`layer_names`**:`StrList`=***`['weight_hh_l0']`***) :: [`PrePostInitMeta`](/core.html#PrePostInitMeta) :: [`Module`](/torch_core.html#Module)\n", "\n", "<div class=\"collapse\" id=\"WeightDropout-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#WeightDropout-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>WeightDropout</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div>\n", "\n", "A module that warps another layer in which some weights will be replaced by 0 during training.  "], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}], "source": ["show_doc(WeightDropout, title_level=3)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Aplica-se abandono de probabilidade `weight_p` \u00e0s camadas em` layer_names` de `module` no modo de treino. Uma c\u00f3pia desses pesos \u00e9 mantido para que a m\u00e1scara de abandono pode mudar em cada lote."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"data": {"text/plain": ["Parameter containing:\n", "tensor([[-0.0702,  0.5725],\n", "        [-0.3910,  0.6512],\n", "        [-0.2203, -0.4315],\n", "        [ 0.2750, -0.2917],\n", "        [-0.4890, -0.3094],\n", "        [ 0.4638, -0.3807],\n", "        [-0.2290, -0.6964],\n", "        [ 0.1224,  0.4043]], requires_grad=True)"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["module = nn.LSTM(5, 2)\n", "dp_module = WeightDropout(module, 0.4)\n", "getattr(dp_module.module, 'weight_hh_l0')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\u00c9, no in\u00edcio de uma passagem para a frente que o abandono \u00e9 aplicado aos pesos."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"data": {"text/plain": ["tensor([[-0.0000,  0.0000],\n", "        [-0.6517,  0.0000],\n", "        [-0.0000, -0.7191],\n", "        [ 0.4583, -0.0000],\n", "        [-0.0000, -0.0000],\n", "        [ 0.7730, -0.6345],\n", "        [-0.0000, -1.1607],\n", "        [ 0.2040,  0.6739]], grad_fn=<MulBackward0>)"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["tst_input = torch.randn(4,20,5)\n", "h = (torch.zeros(1,20,2), torch.zeros(1,20,2))\n", "x,h = dp_module(tst_input,h)\n", "getattr(dp_module.module, 'weight_hh_l0')"]}, {"cell_type": "code", "execution_count": null, "metadata": {"hide_input": true}, "outputs": [{"data": {"text/markdown": ["<h3 id=\"PositionalEncoding\" class=\"doc_header\"><code>class</code> <code>PositionalEncoding</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/models/transformer.py#L11\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#PositionalEncoding-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h3>\n", "\n", "> <code>PositionalEncoding</code>(**`d`**:`int`) :: [`PrePostInitMeta`](/core.html#PrePostInitMeta) :: [`Module`](/torch_core.html#Module)\n", "\n", "<div class=\"collapse\" id=\"PositionalEncoding-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#PositionalEncoding-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>PositionalEncoding</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div>\n", "\n", "Encode the position with a sinusoid.  "], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}], "source": ["show_doc(PositionalEncoding, title_level=3)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"hide_input": true}, "outputs": [{"data": {"text/markdown": ["<h3 id=\"DecoderLayer\" class=\"doc_header\"><code>class</code> <code>DecoderLayer</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/models/transformer.py#L138\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#DecoderLayer-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h3>\n", "\n", "> <code>DecoderLayer</code>(**`n_heads`**:`int`, **`d_model`**:`int`, **`d_head`**:`int`, **`d_inner`**:`int`, **`resid_p`**:`float`=***`0.0`***, **`attn_p`**:`float`=***`0.0`***, **`ff_p`**:`float`=***`0.0`***, **`bias`**:`bool`=***`True`***, **`scale`**:`bool`=***`True`***, **`act`**:[`Activation`](/text.models.transformer.html#Activation)=***`<Activation.ReLU: 1>`***, **`double_drop`**:`bool`=***`True`***, **`attn_cls`**:`Callable`=***`'MultiHeadAttention'`***) :: [`PrePostInitMeta`](/core.html#PrePostInitMeta) :: [`Module`](/torch_core.html#Module)\n", "\n", "<div class=\"collapse\" id=\"DecoderLayer-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#DecoderLayer-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>DecoderLayer</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div>\n", "\n", "Basic block of a Transformer model.  "], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}], "source": ["show_doc(DecoderLayer, title_level=3)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"hide_input": true}, "outputs": [{"data": {"text/markdown": ["<h3 id=\"MultiHeadAttention\" class=\"doc_header\"><code>class</code> <code>MultiHeadAttention</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/models/transformer.py#L33\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#MultiHeadAttention-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h3>\n", "\n", "> <code>MultiHeadAttention</code>(**`n_heads`**:`int`, **`d_model`**:`int`, **`d_head`**:`int`=***`None`***, **`resid_p`**:`float`=***`0.0`***, **`attn_p`**:`float`=***`0.0`***, **`bias`**:`bool`=***`True`***, **`scale`**:`bool`=***`True`***) :: [`PrePostInitMeta`](/core.html#PrePostInitMeta) :: [`Module`](/torch_core.html#Module)\n", "\n", "<div class=\"collapse\" id=\"MultiHeadAttention-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#MultiHeadAttention-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>MultiHeadAttention</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div>\n", "\n", "MutiHeadAttention.  "], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}], "source": ["show_doc(MultiHeadAttention, title_level=3)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"hide_input": true}, "outputs": [{"data": {"text/markdown": ["<h3 id=\"MultiHeadRelativeAttention\" class=\"doc_header\"><code>class</code> <code>MultiHeadRelativeAttention</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/models/transformer.py#L89\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#MultiHeadRelativeAttention-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h3>\n", "\n", "> <code>MultiHeadRelativeAttention</code>(**`n_heads`**:`int`, **`d_model`**:`int`, **`d_head`**:`int`, **`resid_p`**:`float`=***`0.0`***, **`attn_p`**:`float`=***`0.0`***, **`bias`**:`bool`=***`True`***, **`scale`**:`bool`=***`True`***) :: [`PrePostInitMeta`](/core.html#PrePostInitMeta) :: [`MultiHeadAttention`](/text.models.transformer.html#MultiHeadAttention)\n", "\n", "<div class=\"collapse\" id=\"MultiHeadRelativeAttention-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#MultiHeadRelativeAttention-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>MultiHeadRelativeAttention</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div>\n", "\n", "MutiHeadAttention with relative positional encoding.  "], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}], "source": ["show_doc(MultiHeadRelativeAttention, title_level=3)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"hide_input": true}, "outputs": [{"data": {"text/markdown": ["<h3 id=\"SequentialRNN\" class=\"doc_header\"><code>class</code> <code>SequentialRNN</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/models/awd_lstm.py#L153\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#SequentialRNN-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h3>\n", "\n", "> <code>SequentialRNN</code>(**\\*`args`**) :: [`Sequential`](https://pytorch.org/docs/stable/nn.html#torch.nn.Sequential)\n", "\n", "<div class=\"collapse\" id=\"SequentialRNN-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#SequentialRNN-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>SequentialRNN</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div>\n", "\n", "A sequential module that passes the reset call to its children.  "], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}], "source": ["show_doc(SequentialRNN, title_level=3)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"hide_input": true}, "outputs": [{"data": {"text/markdown": ["<h4 id=\"SequentialRNN.reset\" class=\"doc_header\"><code>reset</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/models/awd_lstm.py#L155\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#SequentialRNN-reset-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h4>\n", "\n", "> <code>reset</code>()\n", "\n", "<div class=\"collapse\" id=\"SequentialRNN-reset-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#SequentialRNN-reset-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>reset</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div>"], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}], "source": ["show_doc(SequentialRNN.reset)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Chamar o `fun\u00e7\u00e3o reset` de [`self.children`](/torch_core.html#children) (se tiver)."]}, {"cell_type": "code", "execution_count": null, "metadata": {"hide_input": true}, "outputs": [{"data": {"text/markdown": ["<h4 id=\"dropout_mask\" class=\"doc_header\"><code>dropout_mask</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/models/awd_lstm.py#L13\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#dropout_mask-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h4>\n", "\n", "> <code>dropout_mask</code>(**`x`**:`Tensor`, **`sz`**:`Collection`\\[`int`\\], **`p`**:`float`)\n", "\n", "<div class=\"collapse\" id=\"dropout_mask-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#dropout_mask-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>dropout_mask</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div>\n", "\n", "Return a dropout mask of the same type as `x`, size `sz`, with probability `p` to cancel an element.  "], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}], "source": ["show_doc(dropout_mask)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"data": {"text/plain": ["tensor([[0.0000, 1.4286, 1.4286, 0.0000, 1.4286, 1.4286, 0.0000],\n", "        [1.4286, 1.4286, 1.4286, 0.0000, 1.4286, 0.0000, 0.0000],\n", "        [1.4286, 0.0000, 1.4286, 0.0000, 0.0000, 0.0000, 1.4286]])"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["tst_input = torch.randn(3,3,7)\n", "dropout_mask(tst_input, (3,7), 0.3)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Uma tal m\u00e1scara \u00e9, ent\u00e3o, expandido na dimens\u00e3o do comprimento e sequ\u00eancia multiplicado pela entrada fazer uma [`RNNDropout`](/text.models.awd_lstm.html#RNNDropout)."]}, {"cell_type": "code", "execution_count": null, "metadata": {"hide_input": true}, "outputs": [{"data": {"text/markdown": ["<h4 id=\"feed_forward\" class=\"doc_header\"><code>feed_forward</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/models/transformer.py#L28\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#feed_forward-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h4>\n", "\n", "> <code>feed_forward</code>(**`d_model`**:`int`, **`d_ff`**:`int`, **`ff_p`**:`float`=***`0.0`***, **`act`**:[`Activation`](/text.models.transformer.html#Activation)=***`<Activation.ReLU: 1>`***, **`double_drop`**:`bool`=***`True`***)\n", "\n", "<div class=\"collapse\" id=\"feed_forward-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#feed_forward-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>feed_forward</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div>"], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}], "source": ["show_doc(feed_forward)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Indocumentados M\u00e9todos - M\u00e9todos movidos abaixo desta linha ir\u00e1 intencionalmente ser escondido"]}, {"cell_type": "code", "execution_count": null, "metadata": {"hide_input": false}, "outputs": [{"data": {"text/markdown": ["<h4 id=\"WeightDropout.forward\" class=\"doc_header\"><code>forward</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/models/awd_lstm.py#L44\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#WeightDropout-forward-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h4>\n", "\n", "> <code>forward</code>(**\\*`args`**:`ArgStar`)\n", "\n", "<div class=\"collapse\" id=\"WeightDropout-forward-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#WeightDropout-forward-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>forward</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div>\n", "\n", "Defines the computation performed at every call. Should be overridden by all subclasses.\n", "\n", ".. note::\n", "    Although the recipe for forward pass needs to be defined within\n", "    this function, one should call the :class:[`Module`](/torch_core.html#Module) instance afterwards\n", "    instead of this since the former takes care of running the\n", "    registered hooks while the latter silently ignores them. "], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}], "source": ["show_doc(WeightDropout.forward)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"hide_input": false}, "outputs": [{"data": {"text/markdown": ["<h4 id=\"EmbeddingDropout.forward\" class=\"doc_header\"><code>forward</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/models/awd_lstm.py#L65\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#EmbeddingDropout-forward-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h4>\n", "\n", "> <code>forward</code>(**`words`**:`LongTensor`, **`scale`**:`Optional`\\[`float`\\]=***`None`***) \u2192 `Tensor`\n", "\n", "<div class=\"collapse\" id=\"EmbeddingDropout-forward-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#EmbeddingDropout-forward-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>forward</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div>\n", "\n", "Defines the computation performed at every call. Should be overridden by all subclasses.\n", "\n", ".. note::\n", "    Although the recipe for forward pass needs to be defined within\n", "    this function, one should call the :class:[`Module`](/torch_core.html#Module) instance afterwards\n", "    instead of this since the former takes care of running the\n", "    registered hooks while the latter silently ignores them. "], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}], "source": ["show_doc(EmbeddingDropout.forward)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"hide_input": false}, "outputs": [{"data": {"text/markdown": ["<h4 id=\"RNNDropout.forward\" class=\"doc_header\"><code>forward</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/models/awd_lstm.py#L22\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#RNNDropout-forward-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h4>\n", "\n", "> <code>forward</code>(**`x`**:`Tensor`) \u2192 `Tensor`\n", "\n", "<div class=\"collapse\" id=\"RNNDropout-forward-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#RNNDropout-forward-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>forward</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div>\n", "\n", "Defines the computation performed at every call. Should be overridden by all subclasses.\n", "\n", ".. note::\n", "    Although the recipe for forward pass needs to be defined within\n", "    this function, one should call the :class:[`Module`](/torch_core.html#Module) instance afterwards\n", "    instead of this since the former takes care of running the\n", "    registered hooks while the latter silently ignores them. "], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}], "source": ["show_doc(RNNDropout.forward)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"data": {"text/markdown": ["<h4 id=\"WeightDropout.reset\" class=\"doc_header\"><code>reset</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/models/awd_lstm.py#L51\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#WeightDropout-reset-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h4>\n", "\n", "> <code>reset</code>()\n", "\n", "<div class=\"collapse\" id=\"WeightDropout-reset-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#WeightDropout-reset-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>reset</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div>"], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}], "source": ["show_doc(WeightDropout.reset)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"data": {"text/markdown": ["<h4 id=\"PoolingLinearClassifier.forward\" class=\"doc_header\"><code>forward</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/learner.py#L240\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#PoolingLinearClassifier-forward-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h4>\n", "\n", "> <code>forward</code>(**`input`**:`Tuple`\\[`Tensor`, `Tensor`, `Tensor`\\]) \u2192 `Tuple`\\[`Tensor`, `Tensor`, `Tensor`\\]\n", "\n", "<div class=\"collapse\" id=\"PoolingLinearClassifier-forward-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#PoolingLinearClassifier-forward-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>forward</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div>\n", "\n", "Defines the computation performed at every call. Should be overridden by all subclasses.\n", "\n", ".. note::\n", "    Although the recipe for forward pass needs to be defined within\n", "    this function, one should call the :class:[`Module`](/torch_core.html#Module) instance afterwards\n", "    instead of this since the former takes care of running the\n", "    registered hooks while the latter silently ignores them. "], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}], "source": ["show_doc(PoolingLinearClassifier.forward)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"data": {"text/markdown": ["<h4 id=\"LinearDecoder.forward\" class=\"doc_header\"><code>forward</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/models/awd_lstm.py#L147\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#LinearDecoder-forward-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h4>\n", "\n", "> <code>forward</code>(**`input`**:`Tuple`\\[`Tensor`, `Tensor`\\]) \u2192 `Tuple`\\[`Tensor`, `Tensor`, `Tensor`\\]\n", "\n", "<div class=\"collapse\" id=\"LinearDecoder-forward-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#LinearDecoder-forward-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>forward</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div>\n", "\n", "Defines the computation performed at every call. Should be overridden by all subclasses.\n", "\n", ".. note::\n", "    Although the recipe for forward pass needs to be defined within\n", "    this function, one should call the :class:[`Module`](/torch_core.html#Module) instance afterwards\n", "    instead of this since the former takes care of running the\n", "    registered hooks while the latter silently ignores them. "], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}], "source": ["show_doc(LinearDecoder.forward)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Novos M\u00e9todos - Por favor, documento ou mover para a se\u00e7\u00e3o em situa\u00e7\u00e3o irregular"]}], "metadata": {"jekyll": {"keywords": "fastai", "summary": "Implementation of the AWD-LSTM and the RNN models", "title": "text.models"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}, "nbformat": 4, "nbformat_minor": 2}